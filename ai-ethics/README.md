#### Discussion

* [Cathy O’Neil Twitter Discussion 'Algorithms are a threat to society and so far, academia is asleep at the wheel.'](https://twitter.com/mathbabedotorg/status/930429461165760512)

####  Discussion
* [AI Ethics on Reddit](https://www.reddit.com/r/AIethics/)
* [(HN) Attacking discrimination with smarter machine learning](https://news.ycombinator.com/item?id=13004790)
* [(HN) Cathy O’Neil on Weapons of Math Destruction](https://news.ycombinator.com/item?id=12642432)
* [(HN) on Neural Net Trained on Mugshots Predicts Criminals](https://news.ycombinator.com/item?id=13034116)
* [(HN) Justice.exe: Bias in Algorithmic sentencing ](https://news.ycombinator.com/item?id=14285116)

####  Podcast

* [EconTalk Episode with Cathy O'Neil](http://www.econtalk.org/archives/2016/10/cathy_oneil_on_1.html)
* [Machine Ethic Podcasts](http://machine-ethics.net/podcast/)

####  Videos

* [Ethics of Artificial Intelligence conference NYU 2016](https://livestream.com/nyu-tv/ethicsofAI/)
* [A Story of Discrimination and Unfairness - Aylin Caliskan 33c3 2016](https://media.ccc.de/v/33c3-8026-a_story_of_discrimination_and_unfairness)
* [AI Now 2017 Symposium](https://www.youtube.com/watch?v=npL_UsK_npE)
* [The Trouble with Bias - NIPS 2017 Keynote](https://www.youtube.com/watch?v=fMym_BKWQzk)
* [Eyeo 2018 - Meredith Whittaker - DATA GENESIS: AI'S PRIMORDIAL SOUP](https://vimeo.com/287094149)
* ["Privacy: the Last Stand for Fair Algorithms" by Katharine Jarmul](https://www.youtube.com/watch?v=j4WRv6GNuDM)

####  Papers 

* [Bias in Computer Systems](https://www.nyu.edu/projects/nissenbaum/papers/biasincomputers.pdf)
* [Equality of Opportunity in Supervised Learning](https://drive.google.com/file/d/0B-wQVEjH9yuhanpyQjUwQS1JOTQ/view)
* [Using sensitive personal data may be necessary for avoiding discrimination in data-driven decision models](https://sites.google.com/site/zliobaitefiles2/Zliobaite_fair_regression.pdf?attredirects=1)
* [The Ethics of Artificial Intelligence](http://www.nickbostrom.com/ethics/artificial-intelligence.pdf)
* [Automated Inference on Criminality using Face Images](https://arxiv.org/abs/1611.04135)
* [Semantics derived automatically from language corpora contain human-like biases](http://opus.bath.ac.uk/55288/)
* [European Union regulations on algorithmic decision-making and a "right to explanation"](https://arxiv.org/abs/1606.08813)
* [Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints](https://homes.cs.washington.edu/~my89/publications/bias.pdf)
* [Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings](https://arxiv.org/abs/1607.06520)
* [Deep neural networks are more accurate than humans at detecting sexual orientation from facial images.](https://osf.io/zn79k/)
* [Delayed Impact of Fair Machine Learning](http://bair.berkeley.edu/blog/2018/05/17/delayed-impact/)
* [Bias detectives: the researchers striving to make algorithms fair](https://www.nature.com/articles/d41586-018-05469-3)
* [ No Classification without Representation: Assessing Geodiversity Issues in Open Data Sets for the Developing World](https://arxiv.org/abs/1711.08536)
####  Books

* [Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy](https://www.amazon.com/Weapons-Math-Destruction-Increases-Inequality/dp/0553418815/ref=sr_1_1?ie=UTF8&qid=1479818920&sr=8-1&keywords=Weapons-Math-Destruction-Increases-Inequality)
* [Interpretable Machine Learning A Guide for Making Black Box Models Explainable.](https://christophm.github.io/interpretable-ml-book/)
* [Fairness and machine learning book](http://fairmlbook.org/)

####  Articles
* [Algorithms: AI’s creepy control must be open to inspection](https://www.theguardian.com/commentisfree/2017/jan/01/algorithms-ai-artificial-intelligence-facebook-accountability)
* [AI watchdog needed to regulate automated decision-making, say experts](https://www.theguardian.com/technology/2017/jan/27/ai-artificial-intelligence-watchdog-needed-to-prevent-discriminatory-automated-decisions)
* [Scholars Delve Deeper Into The Ethics Of Artificial Intelligence](http://www.npr.org/sections/alltechconsidered/2016/11/21/502905772/scholars-delve-deeper-into-the-ethics-of-artificial-intelligence)
* [ProPublica series on Machine Bias](https://www.propublica.org/series/machine-bias)
* [Artificial Intelligence’s White Guy Problem](http://www.nytimes.com/2016/06/26/opinion/sunday/artificial-intelligences-white-guy-problem.html)
* [Neural Net Trained on Mugshots Predicts Criminals](https://www.technologyreview.com/s/602955/neural-network-learns-to-identify-criminals-by-their-faces/)
* [Attacking discrimination with smarter machine learning](http://research.google.com/bigpicture/attacking-discrimination-in-ml/)
* [The Ethical Data Scientis](http://www.slate.com/articles/technology/future_tense/2016/02/how_to_bring_better_ethics_to_data_science.html)
* [Machine Bias](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)
* [Machine Bias - How We Analyzed the COMPAS Recidivism Algorithm](https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm)
* [ProPublica Responds to Company’s Critique of Machine Bias Story](https://www.propublica.org/article/propublica-responds-to-companys-critique-of-machine-bias-story)
* [Are Machines Biased, or Are We Biased Against Machines?](http://alex.miller.im/posts/are-we-biased-against-machines-propublica-recidivism/)
* [Artificial Intelligence’s White Guy Problem](http://www.nytimes.com/2016/06/26/opinion/sunday/artificial-intelligences-white-guy-problem.html)
* [Buyer Beware: A hard look at police ‘threat scores.’](https://www.equalfuture.us/2016/01/14/buyer-beware-police-threat-scores/)
* [Computer and Information Ethics](http://plato.stanford.edu/entries/ethics-computer/)
* [Social Networking and Ethics](http://plato.stanford.edu/entries/ethics-social-networking/)
* [Internet Research Ethics](http://plato.stanford.edu/entries/ethics-internet-research/)
* [Search Engines and Ethics](http://plato.stanford.edu/entries/ethics-search/)
* [How a Machine Learns Prejudice](https://www.scientificamerican.com/article/how-a-machine-learns-prejudice/)
* [Courts Are Using AI to Sentence Criminals. That Must Stop Now](https://www.wired.com/2017/04/courts-using-ai-sentence-criminals-must-stop-now/)
* [Sent to Prison by a Software Program’s Secret Algorithms](https://www.nytimes.com/2017/05/01/us/politics/sent-to-prison-by-a-software-programs-secret-algorithms.html)
* [Even artificial intelligence can acquire biases against race and gender](http://www.sciencemag.org/news/2017/04/even-artificial-intelligence-can-acquire-biases-against-race-and-gender)
* [Inspecting Algorithms for Bias](https://www.technologyreview.com/s/607955/inspecting-algorithms-for-bias/)
* [If you’re not a white male, artificial intelligence’s use in healthcare could be dangerous](https://qz.com/1023448/if-youre-not-a-white-male-artificial-intelligences-use-in-healthcare-could-be-dangerous/)
* [Biased Algorithms Are Everywhere, and No One Seems to Care](https://www.technologyreview.com/s/608248/biased-algorithms-are-everywhere-and-no-one-seems-to-care/)
* [Turns Out Algorithms Are Racist](https://newrepublic.com/article/144644/turns-algorithms-racist)
* [Machines Taught by Photos Learn a Sexist View of Women](https://www.wired.com/story/machines-taught-by-photos-learn-a-sexist-view-of-women/)
* [How Tech Giants Are Devising Real Ethics for Artificial Intelligence](https://www.nytimes.com/2016/09/02/technology/artificial-intelligence-ethics.html)
* [New AI can guess whether you're gay or straight from a photograph](https://www.theguardian.com/technology/2017/sep/07/new-artificial-intelligence-can-tell-whether-youre-gay-or-straight-from-a-photograph)
* [Something is wrong on the internet, on youtube automated videos by James Bridle](https://medium.com/@jamesbridle/something-is-wrong-on-the-internet-c39c471271d2)
* [Trump’s “extreme-vetting” software will discriminate against immigrants “under a veneer of objectivity,” say experts](https://theintercept.com/2017/11/16/trumps-extreme-vetting-software-will-discriminate-against-immigrants-under-a-veneer-of-objectivity-say-experts/)
* [ACLU calls out Amazon, Washington Co. sheriff's office for facial recognition tech](https://www.kgw.com/article/money/aclu-calls-out-amazon-washington-co-sheriffs-office-for-facial-recognition-tech/283-557099068)
* [This startup’s racial-profiling algorithm shows AI can be dangerous way before any robot apocalypse](https://qz.com/1286533/a-startup-selling-racial-profiling-software-shows-how-ai-can-be-dangerous-way-before-any-robot-apocalypse/)
* [Facial recognition software is not ready for use by law enforcement](https://techcrunch.com/2018/06/25/facial-recognition-software-is-not-ready-for-use-by-law-enforcement/)
* [Prescription: AI - Quartz series](https://qz.com/se/prescription-ai/)
* [Amazon scraps secret AI recruiting tool that showed bias against women](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G)
* [A skeptic’s guide to thinking about AI -  on AI Now 2018](https://www.fastcompany.com/90252753/a-skeptics-guide-to-thinking-about-ai)

####  Others
* [Machine ethics: The robot’s dilemma](http://www.nature.com/news/machine-ethics-the-robot-s-dilemma-1.17881)
* [Morals and the machine](http://www.economist.com/node/21556234)
* [Robotics: Ethics of artificial intelligence](http://www.nature.com/news/robotics-ethics-of-artificial-intelligence-1.17611)
* [Do no harm, don't discriminate: official guidance issued on robot ethics](https://www.theguardian.com/technology/2016/sep/18/official-guidance-robot-ethics-british-standards-institute)
* ["RoboCop” assignment Columbia University NYPD’s “Stop, Question and Frisk” records](http://columbialion.com/colorcode-statement-on-coms-4771-stop-and-frisk-competition/)
* [Professor Satyen Kale Responds to ‘RoboCop’ Machine Learning Assignment](http://columbialion.com/professor-satyen-kale-responds-to-robocop-ml-assignment/)
* [White House document: Preparing for the Future of Artificial Intelligence](https://www.whitehouse.gov/sites/default/files/whitehouse_files/microsites/ostp/NSTC/preparing_for_the_future_of_ai.pdf)
* [Justice.exe - Educative Game](http://justiceexe.com/index.html)
* [mathwashing](http://www.mathwashing.com/)
* [ConceptNet Numberbatch 17.04: better, less-stereotyped word vectors](https://blog.conceptnet.io/2017/04/24/conceptnet-numberbatch-17-04-better-less-stereotyped-word-vectors/)
* [Research on Algorithmic Fairness, haverford](http://fairness.haverford.edu/)
* [NORMAN World's first psychopath AI](http://norman-ai.mit.edu/)
* [AI can be sexist and racist — it’s time to make it fair](https://www.nature.com/articles/d41586-018-05707-8)

####  Reports
* [ARTIFICIAL INTELLIGENCE AND LIFE IN 2030 - 2016 Report](https://ai100.stanford.edu/2016-report)

####  Conferences, Workshops, Symposiums 

* [Workshop on Fairness, Accountability, and Transparency in Machine Learning](http://www.fatml.org/)
* [AI Now](https://artificialintelligencenow.com/schedule/2017-symposium)
* [Ethics of Artificial Intelligence](https://wp.nyu.edu/consciousness/ethics-of-artificial-intelligence/)
* [Black in AI](http://ai.stanford.edu/~tgebru/blackAI)
* [Algorithms and Explanations](http://www.law.nyu.edu/centers/ili/events/algorithms-and-explanations)
* [Machine Learning and the Law](http://www.mlandthelaw.org/)
* [Ethics in Mathematics - Cambridge University](http://www.ethics.maths.cam.ac.uk/EiM1/)
* [AI Now 2018 Symposium - video](https://www.youtube.com/watch?v=NmdAtfcmTNg)

#### Classes

* [Fairness in Machine Learning](https://fairmlclass.github.io/)
* [INFO 4270: ETHICS AND POLICY IN DATA SCIENCE](https://docs.google.com/document/d/1GV97qqvjQNvyM2I01vuRaAwHe9pQAZ9pbP7KkKveg1o/)
* [CS109: Ethical Foundations of Computer Science](https://www.cs.utexas.edu/~ans/classes/cs109/schedule.html)
* [An Introduction to Data Ethics](https://www.scu.edu/ethics/focus-areas/technology-ethics/resources/an-introduction-to-data-ethics/)
* [Machine Learning Fairness by Google](https://developers.google.com/machine-learning/crash-course/fairness/video-lecture)

#### Lists 

* [A critical reading list for engineers, designers, and policy makers](https://github.com/rockita/criticalML)
* [Awesome-Machine-Learning-Interpretability](https://github.com/jphall663/awesome-machine-learning-interpretability)
* [Fast AI Ethics Resources](https://www.fast.ai/2018/09/24/ai-ethics-resources/)
####  People and Organizations

* [Kate Crawford](http://www.katecrawford.net/)
* [Meredith Whittaker](https://twitter.com/mer__edith)
* [Kate Darling](https://twitter.com/grok_)
* [Cathy O'Neil](https://mathbabe.org/)
* [Alan Winfield](https://alanwinfield.blogspot.com/)
* [AI Now](https://artificialintelligencenow.com/)
* [Algorithm Watch](https://algorithmwatch.org)
* [Moritz Hardt](http://moritzhardt.com/)
* [Solon Barocas](http://solon.barocas.org/)
* [Institute for Ethics and Emerging Technologies](https://ieet.org/)
* [The Center for Technology, Society & Policy Berkley](https://twitter.com/CTSPBerkeley)
* [Zeynep Tufekci](https://twitter.com/zeynep)
* [Data & Society](https://datasociety.net/about/)
* [PERVADE: Pervasive Data Ethics](https://pervade.umd.edu/)
* [DataEthics](https://dataethics.eu/en/)
